{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "758eb6ee",
   "metadata": {},
   "source": [
    " =============================================================\n",
    "### 01 - Exploratory Data Analysis\n",
    " ============================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0bf1e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Imports & Setup ---\n",
    "import pandas as pd\n",
    "import html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ef9f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Work\\AppData\\Local\\Temp\\ipykernel_8824\\3553111191.py:3: DtypeWarning: Columns (0: name, 1: reviews.didPurchase) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  ds1 = pd.read_csv(\"../data/1429_1.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34660, 21)\n",
      "id                          str\n",
      "name                        str\n",
      "asins                       str\n",
      "brand                       str\n",
      "categories                  str\n",
      "keys                        str\n",
      "manufacturer                str\n",
      "reviews.date                str\n",
      "reviews.dateAdded           str\n",
      "reviews.dateSeen            str\n",
      "reviews.didPurchase      object\n",
      "reviews.doRecommend      object\n",
      "reviews.id              float64\n",
      "reviews.numHelpful      float64\n",
      "reviews.rating          float64\n",
      "reviews.sourceURLs          str\n",
      "reviews.text                str\n",
      "reviews.title               str\n",
      "reviews.userCity        float64\n",
      "reviews.userProvince    float64\n",
      "reviews.username            str\n",
      "dtype: object\n",
      "\n",
      "\n",
      "(5000, 24)\n",
      "id                         str\n",
      "dateAdded                  str\n",
      "dateUpdated                str\n",
      "name                       str\n",
      "asins                      str\n",
      "brand                      str\n",
      "categories                 str\n",
      "primaryCategories          str\n",
      "imageURLs                  str\n",
      "keys                       str\n",
      "manufacturer               str\n",
      "manufacturerNumber         str\n",
      "reviews.date               str\n",
      "reviews.dateAdded          str\n",
      "reviews.dateSeen           str\n",
      "reviews.doRecommend       bool\n",
      "reviews.id             float64\n",
      "reviews.numHelpful       int64\n",
      "reviews.rating           int64\n",
      "reviews.sourceURLs         str\n",
      "reviews.text               str\n",
      "reviews.title              str\n",
      "reviews.username           str\n",
      "sourceURLs                 str\n",
      "dtype: object\n",
      "\n",
      "\n",
      "(28332, 24)\n",
      "id                         str\n",
      "dateAdded                  str\n",
      "dateUpdated                str\n",
      "name                       str\n",
      "asins                      str\n",
      "brand                      str\n",
      "categories                 str\n",
      "primaryCategories          str\n",
      "imageURLs                  str\n",
      "keys                       str\n",
      "manufacturer               str\n",
      "manufacturerNumber         str\n",
      "reviews.date               str\n",
      "reviews.dateSeen           str\n",
      "reviews.didPurchase     object\n",
      "reviews.doRecommend     object\n",
      "reviews.id             float64\n",
      "reviews.numHelpful     float64\n",
      "reviews.rating           int64\n",
      "reviews.sourceURLs         str\n",
      "reviews.text               str\n",
      "reviews.title              str\n",
      "reviews.username           str\n",
      "sourceURLs                 str\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# --- 2. Load Data ---\n",
    "\n",
    "ds1 = pd.read_csv(\"../data/1429_1.csv\")\n",
    "ds2 = pd.read_csv(\"../data/amazon_customer_reviews_2017_2018.csv\")\n",
    "ds3 = pd.read_csv(\"../data/amazon_customer_reviews_Feb_April_2019.csv\")\n",
    "\n",
    "print(ds1.shape)\n",
    "print(ds1.dtypes)\n",
    "print(\"\\n\")\n",
    "print(ds2.shape)\n",
    "print(ds2.dtypes)\n",
    "print(\"\\n\")\n",
    "print(ds3.shape)\n",
    "print(ds3.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11c1538",
   "metadata": {},
   "source": [
    "### Visualization of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc911cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c45d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds1.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da936a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ceee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fa1bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81284d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c42fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# See the Electronics products in detail\n",
    "electronics_ds3 = ds3[ds3[\"primaryCategories\"] == \"Electronics\"]\n",
    "print(electronics_ds3[\"name\"].value_counts().head(30))\n",
    "\n",
    "# Also check data_01 product names since it's all electronics\n",
    "print(ds1[\"name\"].value_counts().head(30))\n",
    "\n",
    "# And review counts per product in Electronics\n",
    "# (thin review counts = thin generation material)\n",
    "print(electronics_ds3.groupby(\"name\")[\"reviews.text\"].count().sort_values(ascending=False).head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b884b258",
   "metadata": {},
   "source": [
    "### Decision on meta-categories\n",
    "\n",
    "Rather than forcing artificial diversity across low-signal categories, we made a deliberate choice to go deep within Electronics — a domain with sufficient product breadth and review volume to produce meaningful generation output. Our 5 sub-categories reflect natural product families that consumers actually compare when making purchase decisions, mirroring how sites like The Wirecutter structure their buying guides"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcfbe5c",
   "metadata": {},
   "source": [
    "### The Cleaning Tasks Per Column\n",
    "\n",
    "```python\n",
    "KEEP = {\n",
    "    \"name\"            → name_clean       # product identity for clustering/generation\n",
    "    \"reviews.rating\"  → rating           # sentiment labels\n",
    "    \"reviews.text\"    → review_text      # the core input for all 3 models\n",
    "    \"primaryCategories\" → primary_category  # DS2/DS3 only, clustering reference\n",
    "    \"brand\"           → brand            # useful context for generation\n",
    "}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**`reviews.text` (most important)**\n",
    "\n",
    "- Drop nulls\n",
    "- Drop reviews under 20 characters (no signal)\n",
    "- Strip leading/trailing whitespace\n",
    "- Remove the \\r\\n duplication artifact (same as names)\n",
    "- Decode any HTML entities (&amp; → &, etc.)\n",
    "\n",
    "\n",
    "**`name`**\n",
    "\n",
    "- Split on \\r\\n, take first part only\n",
    "- Strip trailing commas and whitespace\n",
    "- Drop nulls (can't assign category without a name)\n",
    "\n",
    "\n",
    "**`reviews.rating`**\n",
    "\n",
    "- Coerce to numeric, errors → NaN\n",
    "- Drop NaN\n",
    "- Cast to int\n",
    "- Drop anything outside 1–5 range (data corruption)\n",
    "\n",
    "\n",
    "**`primaryCategories` (DS2/DS3 only)**\n",
    "\n",
    "- Strip whitespace\n",
    "- Standardize multi-label separator (some use comma, some use comma+space)\n",
    "- Keep as-is otherwise\n",
    "\n",
    "\n",
    "**`brand`**\n",
    "\n",
    "- Strip whitespace\n",
    "- Fill nulls with \"Unknown\" — don't drop rows over a missing brand\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6546dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a dataset \n",
    "\n",
    "def load_raw(path: str, low_memory: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"Load a raw CSV file into a DataFrame.\"\"\"\n",
    "    return pd.read_csv(path, low_memory=low_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438f2fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and Rename\n",
    "\n",
    "def select_columns(df: pd.DataFrame, has_primary_cat: bool = False) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Keep only relevant columns and rename them to standard names.\n",
    "    Gracefully skips columns that don't exist in this dataset.\n",
    "    \"\"\"\n",
    "    keep = [\"name\", \"brand\", \"reviews.rating\", \"reviews.text\"]\n",
    "    if has_primary_cat:\n",
    "        keep.append(\"primaryCategories\")\n",
    "\n",
    "    # Only keep columns that actually exist\n",
    "    existing = [c for c in keep if c in df.columns]\n",
    "    df = df[existing].copy()\n",
    "\n",
    "    return df.rename(columns={\n",
    "        \"reviews.text\":      \"review_text\",\n",
    "        \"reviews.rating\":    \"rating\",\n",
    "        \"primaryCategories\": \"primary_category\",\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "82a227e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual column cleaners\n",
    "\n",
    "def clean_name(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean product name: remove duplication artifact, strip junk.\"\"\"\n",
    "    df[\"name\"] = df[\"name\"].apply(\n",
    "        lambda x: \"\" if not isinstance(x, str) else x\n",
    "    )\n",
    "    df[\"name\"] = (\n",
    "        df[\"name\"]\n",
    "        .str.split(\"\\r\\n\").str[0]\n",
    "        .str.strip(\" ,\")\n",
    "    )\n",
    "    return df[df[\"name\"].str.len() > 0].copy()\n",
    "\n",
    "def clean_review_text(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Clean review text: remove artifacts, decode HTML, drop short reviews.\"\"\"\n",
    "    # Convert to string first, before any chained operation\n",
    "    df[\"review_text\"] = df[\"review_text\"].apply(\n",
    "        lambda x: \"\" if not isinstance(x, str) else x\n",
    "    )\n",
    "    df[\"review_text\"] = (\n",
    "        df[\"review_text\"]\n",
    "        .str.split(\"\\r\\n\").str[0]\n",
    "        .str.strip()\n",
    "        .apply(html.unescape)\n",
    "    )\n",
    "    df = df[df[\"review_text\"].str.len() >= 20].copy() # Remove any review under 20 characters due to low-signal \n",
    "    return df\n",
    "\n",
    "def clean_brand(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Normalize brand: fill nulls, strip whitespace.\"\"\"\n",
    "    if \"brand\" not in df.columns:\n",
    "        return df\n",
    "    df[\"brand\"] = df[\"brand\"].fillna(\"Unknown\").astype(str).str.strip()\n",
    "    return df\n",
    "\n",
    "def clean_primary_category(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize primary_category: fill nulls, strip whitespace,\n",
    "    standardize comma separator.\n",
    "    Handles float NaN values safely.     ← this was your bug\n",
    "    \"\"\"\n",
    "    if \"primary_category\" not in df.columns:\n",
    "        return df\n",
    "    df[\"primary_category\"] = (\n",
    "        df[\"primary_category\"]\n",
    "        .fillna(\"Unknown\")      # kills float NaN before any string ops\n",
    "        .astype(str)            # ensures everything is a string\n",
    "        .str.strip()\n",
    "        .str.replace(\", \", \",\", regex=False)\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def clean_rating(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Coerce rating to int, drop nulls and out-of-range values.\"\"\"\n",
    "    df[\"rating\"] = pd.to_numeric(df[\"rating\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"rating\"])\n",
    "    df[\"rating\"] = df[\"rating\"].astype(int)\n",
    "    return df[df[\"rating\"].between(1, 5)].copy()\n",
    "\n",
    "def clean_primary_category(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize primary_category: fill nulls, strip whitespace,\n",
    "    standardize comma separator.\n",
    "    Handles float NaN values safely.     ← this was your bug\n",
    "    \"\"\"\n",
    "    if \"primary_category\" not in df.columns:\n",
    "        return df\n",
    "    df[\"primary_category\"] = (\n",
    "        df[\"primary_category\"]\n",
    "        .fillna(\"Unknown\")      # kills float NaN before any string ops\n",
    "        .astype(str)            # ensures everything is a string\n",
    "        .str.strip()\n",
    "        .str.replace(\", \", \",\", regex=False)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d991ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to call helper functions\n",
    "\n",
    "def load_and_clean(\n",
    "    path: str,\n",
    "    has_primary_cat: bool = False,\n",
    "    low_memory: bool = False\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Full pipeline: load → select → clean each column → reset index.\n",
    "    \"\"\"\n",
    "    df = load_raw(path, low_memory=low_memory)\n",
    "    df = select_columns(df, has_primary_cat=has_primary_cat)\n",
    "    df = clean_name(df)\n",
    "    df = clean_review_text(df)\n",
    "    df = clean_rating(df)\n",
    "    df = clean_brand(df)\n",
    "    df = clean_primary_category(df)\n",
    "    return df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410e97db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS1: 27,747 rows\n",
      "DS2: 5,000 rows\n",
      "DS3: 25,794 rows\n",
      "\n",
      "── Final clean row counts ──\n",
      "DS1: 27,747 rows | columns: ['name', 'brand', 'rating', 'review_text']\n",
      "DS2: 5,000 rows | columns: ['name', 'brand', 'rating', 'review_text', 'primary_category']\n",
      "DS3: 25,794 rows | columns: ['name', 'brand', 'rating', 'review_text', 'primary_category']\n"
     ]
    }
   ],
   "source": [
    "# ── DS1 ──────────────────────────────────────────────────────\n",
    "raw_ds1 = load_raw(\"../data/1429_1.csv\", low_memory=False)\n",
    "df1 = select_columns(raw_ds1, has_primary_cat=False)\n",
    "df1 = clean_name(df1)\n",
    "df1 = clean_review_text(df1)\n",
    "df1 = clean_rating(df1)\n",
    "df1 = clean_brand(df1)\n",
    "ds1_clean = df1.reset_index(drop=True)\n",
    "print(f\"DS1: {len(ds1_clean):,} rows\")\n",
    "\n",
    "# ── DS2 ──────────────────────────────────────────────────────\n",
    "raw_ds2 = load_raw(\"../data/amazon_customer_reviews_2017_2018.csv\")\n",
    "df2 = select_columns(raw_ds2, has_primary_cat=True)\n",
    "df2 = clean_name(df2)\n",
    "df2 = clean_review_text(df2)\n",
    "df2 = clean_rating(df2)\n",
    "df2 = clean_brand(df2)\n",
    "df2 = clean_primary_category(df2)\n",
    "ds2_clean = df2.reset_index(drop=True)\n",
    "print(f\"DS2: {len(ds2_clean):,} rows\")\n",
    "\n",
    "# ── DS3 ──────────────────────────────────────────────────────\n",
    "raw_ds3 = load_raw(\"../data/amazon_customer_reviews_Feb_April_2019.csv\")\n",
    "df3 = select_columns(raw_ds3, has_primary_cat=True)\n",
    "df3 = clean_name(df3)\n",
    "df3 = clean_review_text(df3)\n",
    "df3 = clean_rating(df3)\n",
    "df3 = clean_brand(df3)\n",
    "df3 = clean_primary_category(df3)\n",
    "ds3_clean = df3.reset_index(drop=True)\n",
    "print(f\"DS3: {len(ds3_clean):,} rows\")\n",
    "\n",
    "# ── Summary ──────────────────────────────────────────────────\n",
    "print(\"\\n── Final clean row counts ──\")\n",
    "for name, dataset in [(\"DS1\", ds1_clean), (\"DS2\", ds2_clean), (\"DS3\", ds3_clean)]:\n",
    "    print(f\"{name}: {len(dataset):,} rows | columns: {dataset.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eabdbd4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "── Sentiment Corpus ──\n",
      "Total reviews: 39,794\n",
      "Class distribution:\n",
      "sentiment\n",
      "positive    36273\n",
      "neutral      1845\n",
      "negative     1676\n",
      "Name: count, dtype: int64\n",
      "Class balance (%):\n",
      "sentiment\n",
      "positive    91.2\n",
      "neutral      4.6\n",
      "negative     4.2\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "── Electronics Corpus ──\n",
      "Total reviews: 30,487\n",
      "Unique products: 80\n",
      "Echo / Tap: 4,270 reviews\n",
      "Fire TV: 2,554 reviews\n",
      "\n",
      "── Saved ──\n",
      "sentiment_ready.csv\n",
      "electronics_ready.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.makedirs(\"../data/processed\", exist_ok=True)\n",
    "\n",
    "# ── Check 1: Sentiment corpus (all three combined) ────────────────────────\n",
    "sentiment_df = pd.concat(\n",
    "    [ds1_clean, ds2_clean, ds3_clean], ignore_index=True\n",
    ").drop_duplicates(subset=[\"review_text\"])\n",
    "\n",
    "# Map ratings to sentiment labels\n",
    "def rating_to_sentiment(rating: int) -> str:\n",
    "    if rating >= 4:\n",
    "        return \"positive\"\n",
    "    elif rating == 3:\n",
    "        return \"neutral\"\n",
    "    return \"negative\"\n",
    "\n",
    "sentiment_df[\"sentiment\"] = sentiment_df[\"rating\"].apply(rating_to_sentiment)\n",
    "\n",
    "print(\"── Sentiment Corpus ──\")\n",
    "print(f\"Total reviews: {len(sentiment_df):,}\")\n",
    "print(f\"Class distribution:\\n{sentiment_df['sentiment'].value_counts()}\")\n",
    "print(f\"Class balance (%):\\n{sentiment_df['sentiment'].value_counts(normalize=True).mul(100).round(1)}\")\n",
    "\n",
    "# ── Check 2: Electronics corpus (clustering + generation) ─────────────────\n",
    "electronics_df = pd.concat([\n",
    "    ds1_clean[[\"name\", \"brand\", \"rating\", \"review_text\"]],\n",
    "    ds3_clean[ds3_clean[\"primary_category\"].str.contains(\"Electronics\", na=False)]\n",
    "             [[\"name\", \"brand\", \"rating\", \"review_text\"]]\n",
    "], ignore_index=True).drop_duplicates(subset=[\"review_text\"])\n",
    "\n",
    "print(\"\\n── Electronics Corpus ──\")\n",
    "print(f\"Total reviews: {len(electronics_df):,}\")\n",
    "print(f\"Unique products: {electronics_df['name'].nunique()}\")\n",
    "\n",
    "# ── Check 3: Echo vs Fire TV split decision ───────────────────────────────\n",
    "for keywords, label in [\n",
    "    ([\"Echo\", \"Tap\"],       \"Echo / Tap\"),\n",
    "    ([\"Fire TV\", \"FireTV\"], \"Fire TV\")\n",
    "]:\n",
    "    count = electronics_df[\"name\"].str.contains(\n",
    "        \"|\".join(keywords), case=False, na=False\n",
    "    ).sum()\n",
    "    print(f\"{label}: {count:,} reviews\")\n",
    "\n",
    "# ── Save processed files ──────────────────────────────────────────────────\n",
    "sentiment_df.to_csv(\"../data/processed/sentiment_ready.csv\", index=False)\n",
    "electronics_df.to_csv(\"../data/processed/electronics_ready.csv\", index=False)\n",
    "print(\"\\n── Saved ──\")\n",
    "print(\"sentiment_ready.csv\")\n",
    "print(\"electronics_ready.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def905ad",
   "metadata": {},
   "source": [
    "## EDA Summary\n",
    "\n",
    "Three raw datasets were cleaned and standardized using a modular pipeline \n",
    "(load → select → clean per column). After removing duplicated rows, the sentiment corpus \n",
    "contains 39,794 reviews with a severe class imbalance: 91.2% positive, 4.6% \n",
    "neutral, 4.2% negative. This will be addressed in training via class weighting \n",
    "and a balanced evaluation set.\n",
    "\n",
    "All three datasets are combined for sentiment training because sentiment is a \n",
    "domain-agnostic task — emotional language patterns generalize across product \n",
    "categories, and maximum review volume reduces imbalance in the minority classes. \n",
    "For clustering and text generation, only DS1 and DS3 are used: DS2 is almost \n",
    "entirely Electronics and adds no category diversity. DS3 provides the labeled \n",
    "primary_category column that serves as ground truth for clustering evaluation, \n",
    "while DS1 contributes additional review volume within the Electronics domain.\n",
    "\n",
    "The electronics corpus contains 30,487 reviews across 80 unique products, \n",
    "organized into 5 meta-categories: Fire Tablets, Fire Kids Edition, Kindle \n",
    "E-Readers, Echo & Smart Speakers, and Fire TV & Streaming. Rather than forcing \n",
    "artificial diversity across sparse non-electronics categories, I decided to go \n",
    "deep within a single domain where sufficient product breadth and review volume \n",
    "exist to produce meaningful clustering and generation output. \n",
    "\n",
    "All processed files are saved to /data/processed/."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
